{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BatteryProject.ModelOne import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from BatteryProject import data\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "        'disc_capa' : 'summary_discharge_capacity.csv',\n",
    "        'dis_ener' : 'summary_discharge_energy.csv',\n",
    "        'temp_avg' : 'summary_temperature_average.csv',\n",
    "        'char_capa' : 'summary_charge_capacity.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.features = features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[550]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/code/TomG13100/BatteryProject/BatteryProject\n",
      "/home/tom/code/TomG13100/BatteryProject/BatteryProject\n",
      "/home/tom/code/TomG13100/BatteryProject/BatteryProject\n",
      "/home/tom/code/TomG13100/BatteryProject/BatteryProject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/code/TomG13100/BatteryProject/BatteryProject/ModelOne/get_features.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_dict[key] = df_dict[key][filter == 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatteryProject.ModelOne.trainer.Trainer at 0x7f7880b7c910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_data(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_capa_0</th>\n",
       "      <th>disc_capa_1</th>\n",
       "      <th>disc_capa_2</th>\n",
       "      <th>disc_capa_3</th>\n",
       "      <th>disc_capa_4</th>\n",
       "      <th>dis_ener_0</th>\n",
       "      <th>dis_ener_1</th>\n",
       "      <th>dis_ener_2</th>\n",
       "      <th>dis_ener_3</th>\n",
       "      <th>dis_ener_4</th>\n",
       "      <th>temp_avg_0</th>\n",
       "      <th>temp_avg_1</th>\n",
       "      <th>temp_avg_2</th>\n",
       "      <th>temp_avg_3</th>\n",
       "      <th>temp_avg_4</th>\n",
       "      <th>char_capa_0</th>\n",
       "      <th>char_capa_1</th>\n",
       "      <th>char_capa_2</th>\n",
       "      <th>char_capa_3</th>\n",
       "      <th>char_capa_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.565188</td>\n",
       "      <td>1.067467</td>\n",
       "      <td>1.068024</td>\n",
       "      <td>1.068579</td>\n",
       "      <td>1.068935</td>\n",
       "      <td>4.810999</td>\n",
       "      <td>3.264619</td>\n",
       "      <td>3.266856</td>\n",
       "      <td>3.269331</td>\n",
       "      <td>3.271012</td>\n",
       "      <td>32.225212</td>\n",
       "      <td>35.104530</td>\n",
       "      <td>35.114437</td>\n",
       "      <td>35.109535</td>\n",
       "      <td>35.111115</td>\n",
       "      <td>1.450042</td>\n",
       "      <td>1.075779</td>\n",
       "      <td>1.078900</td>\n",
       "      <td>1.080898</td>\n",
       "      <td>1.081935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.687610</td>\n",
       "      <td>1.077328</td>\n",
       "      <td>1.079789</td>\n",
       "      <td>1.081056</td>\n",
       "      <td>1.081895</td>\n",
       "      <td>5.188631</td>\n",
       "      <td>3.274007</td>\n",
       "      <td>3.282055</td>\n",
       "      <td>3.286689</td>\n",
       "      <td>3.289470</td>\n",
       "      <td>29.987286</td>\n",
       "      <td>32.166916</td>\n",
       "      <td>32.020405</td>\n",
       "      <td>32.039341</td>\n",
       "      <td>32.035103</td>\n",
       "      <td>1.158693</td>\n",
       "      <td>1.067526</td>\n",
       "      <td>1.070243</td>\n",
       "      <td>1.071443</td>\n",
       "      <td>1.071736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.969953</td>\n",
       "      <td>1.071395</td>\n",
       "      <td>1.074521</td>\n",
       "      <td>1.076363</td>\n",
       "      <td>1.077149</td>\n",
       "      <td>6.233829</td>\n",
       "      <td>3.257201</td>\n",
       "      <td>3.264633</td>\n",
       "      <td>3.273947</td>\n",
       "      <td>3.276133</td>\n",
       "      <td>29.935772</td>\n",
       "      <td>32.246944</td>\n",
       "      <td>31.896320</td>\n",
       "      <td>32.248268</td>\n",
       "      <td>32.457020</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.071397</td>\n",
       "      <td>1.074246</td>\n",
       "      <td>1.076030</td>\n",
       "      <td>1.076883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.693029</td>\n",
       "      <td>1.070203</td>\n",
       "      <td>1.072951</td>\n",
       "      <td>1.074008</td>\n",
       "      <td>1.074338</td>\n",
       "      <td>5.220398</td>\n",
       "      <td>3.257595</td>\n",
       "      <td>3.266709</td>\n",
       "      <td>3.270271</td>\n",
       "      <td>3.270901</td>\n",
       "      <td>31.028469</td>\n",
       "      <td>33.512745</td>\n",
       "      <td>33.520634</td>\n",
       "      <td>33.527515</td>\n",
       "      <td>33.519550</td>\n",
       "      <td>1.441334</td>\n",
       "      <td>1.066223</td>\n",
       "      <td>1.070237</td>\n",
       "      <td>1.071492</td>\n",
       "      <td>1.072232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.960509</td>\n",
       "      <td>1.071237</td>\n",
       "      <td>1.074817</td>\n",
       "      <td>1.076178</td>\n",
       "      <td>1.076918</td>\n",
       "      <td>6.205605</td>\n",
       "      <td>3.260096</td>\n",
       "      <td>3.271455</td>\n",
       "      <td>3.276207</td>\n",
       "      <td>3.278874</td>\n",
       "      <td>29.662975</td>\n",
       "      <td>31.648550</td>\n",
       "      <td>31.900251</td>\n",
       "      <td>31.955116</td>\n",
       "      <td>32.011055</td>\n",
       "      <td>1.166713</td>\n",
       "      <td>1.077517</td>\n",
       "      <td>1.079837</td>\n",
       "      <td>1.081005</td>\n",
       "      <td>1.081767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.559136</td>\n",
       "      <td>1.062274</td>\n",
       "      <td>1.062889</td>\n",
       "      <td>1.063229</td>\n",
       "      <td>1.063585</td>\n",
       "      <td>4.797898</td>\n",
       "      <td>3.252562</td>\n",
       "      <td>3.255005</td>\n",
       "      <td>3.257560</td>\n",
       "      <td>3.258643</td>\n",
       "      <td>32.607063</td>\n",
       "      <td>36.336994</td>\n",
       "      <td>36.155106</td>\n",
       "      <td>36.285099</td>\n",
       "      <td>36.234791</td>\n",
       "      <td>1.069989</td>\n",
       "      <td>1.071384</td>\n",
       "      <td>1.072463</td>\n",
       "      <td>1.073335</td>\n",
       "      <td>1.073706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.675172</td>\n",
       "      <td>1.082596</td>\n",
       "      <td>1.085115</td>\n",
       "      <td>1.086302</td>\n",
       "      <td>1.086993</td>\n",
       "      <td>5.148950</td>\n",
       "      <td>3.292146</td>\n",
       "      <td>3.300203</td>\n",
       "      <td>3.304393</td>\n",
       "      <td>3.306296</td>\n",
       "      <td>30.271282</td>\n",
       "      <td>33.098038</td>\n",
       "      <td>32.946651</td>\n",
       "      <td>32.972172</td>\n",
       "      <td>32.943546</td>\n",
       "      <td>1.161226</td>\n",
       "      <td>1.069269</td>\n",
       "      <td>1.071042</td>\n",
       "      <td>1.071674</td>\n",
       "      <td>1.072304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.687598</td>\n",
       "      <td>1.077107</td>\n",
       "      <td>1.079873</td>\n",
       "      <td>1.081349</td>\n",
       "      <td>1.082160</td>\n",
       "      <td>5.201485</td>\n",
       "      <td>3.280481</td>\n",
       "      <td>3.289433</td>\n",
       "      <td>3.294489</td>\n",
       "      <td>3.296491</td>\n",
       "      <td>31.151499</td>\n",
       "      <td>33.482254</td>\n",
       "      <td>33.441372</td>\n",
       "      <td>33.448616</td>\n",
       "      <td>33.390770</td>\n",
       "      <td>1.443767</td>\n",
       "      <td>1.067561</td>\n",
       "      <td>1.069810</td>\n",
       "      <td>1.071287</td>\n",
       "      <td>1.072626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.686724</td>\n",
       "      <td>1.080072</td>\n",
       "      <td>1.082439</td>\n",
       "      <td>1.083614</td>\n",
       "      <td>1.084466</td>\n",
       "      <td>5.200130</td>\n",
       "      <td>3.296674</td>\n",
       "      <td>3.303946</td>\n",
       "      <td>3.308346</td>\n",
       "      <td>3.310906</td>\n",
       "      <td>30.226954</td>\n",
       "      <td>33.359642</td>\n",
       "      <td>33.392651</td>\n",
       "      <td>33.479618</td>\n",
       "      <td>33.500774</td>\n",
       "      <td>1.070060</td>\n",
       "      <td>1.071207</td>\n",
       "      <td>1.072014</td>\n",
       "      <td>1.072860</td>\n",
       "      <td>1.074104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.550480</td>\n",
       "      <td>1.057376</td>\n",
       "      <td>1.057529</td>\n",
       "      <td>1.058055</td>\n",
       "      <td>1.058655</td>\n",
       "      <td>4.758062</td>\n",
       "      <td>3.225827</td>\n",
       "      <td>3.227337</td>\n",
       "      <td>3.229618</td>\n",
       "      <td>3.232182</td>\n",
       "      <td>32.506069</td>\n",
       "      <td>35.679821</td>\n",
       "      <td>35.744884</td>\n",
       "      <td>35.736008</td>\n",
       "      <td>35.730583</td>\n",
       "      <td>1.162267</td>\n",
       "      <td>1.079472</td>\n",
       "      <td>1.082149</td>\n",
       "      <td>1.083428</td>\n",
       "      <td>1.084170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     disc_capa_0  disc_capa_1  disc_capa_2  disc_capa_3  disc_capa_4  \\\n",
       "128     1.565188     1.067467     1.068024     1.068579     1.068935   \n",
       "89      1.687610     1.077328     1.079789     1.081056     1.081895   \n",
       "9       1.969953     1.071395     1.074521     1.076363     1.077149   \n",
       "76      1.693029     1.070203     1.072951     1.074008     1.074338   \n",
       "92      1.960509     1.071237     1.074817     1.076178     1.076918   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "98      1.559136     1.062274     1.062889     1.063229     1.063585   \n",
       "21      1.675172     1.082596     1.085115     1.086302     1.086993   \n",
       "102     1.687598     1.077107     1.079873     1.081349     1.082160   \n",
       "62      1.686724     1.080072     1.082439     1.083614     1.084466   \n",
       "96      1.550480     1.057376     1.057529     1.058055     1.058655   \n",
       "\n",
       "     dis_ener_0  dis_ener_1  dis_ener_2  dis_ener_3  dis_ener_4  temp_avg_0  \\\n",
       "128    4.810999    3.264619    3.266856    3.269331    3.271012   32.225212   \n",
       "89     5.188631    3.274007    3.282055    3.286689    3.289470   29.987286   \n",
       "9      6.233829    3.257201    3.264633    3.273947    3.276133   29.935772   \n",
       "76     5.220398    3.257595    3.266709    3.270271    3.270901   31.028469   \n",
       "92     6.205605    3.260096    3.271455    3.276207    3.278874   29.662975   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "98     4.797898    3.252562    3.255005    3.257560    3.258643   32.607063   \n",
       "21     5.148950    3.292146    3.300203    3.304393    3.306296   30.271282   \n",
       "102    5.201485    3.280481    3.289433    3.294489    3.296491   31.151499   \n",
       "62     5.200130    3.296674    3.303946    3.308346    3.310906   30.226954   \n",
       "96     4.758062    3.225827    3.227337    3.229618    3.232182   32.506069   \n",
       "\n",
       "     temp_avg_1  temp_avg_2  temp_avg_3  temp_avg_4  char_capa_0  char_capa_1  \\\n",
       "128   35.104530   35.114437   35.109535   35.111115     1.450042     1.075779   \n",
       "89    32.166916   32.020405   32.039341   32.035103     1.158693     1.067526   \n",
       "9     32.246944   31.896320   32.248268   32.457020     1.448440     1.071397   \n",
       "76    33.512745   33.520634   33.527515   33.519550     1.441334     1.066223   \n",
       "92    31.648550   31.900251   31.955116   32.011055     1.166713     1.077517   \n",
       "..          ...         ...         ...         ...          ...          ...   \n",
       "98    36.336994   36.155106   36.285099   36.234791     1.069989     1.071384   \n",
       "21    33.098038   32.946651   32.972172   32.943546     1.161226     1.069269   \n",
       "102   33.482254   33.441372   33.448616   33.390770     1.443767     1.067561   \n",
       "62    33.359642   33.392651   33.479618   33.500774     1.070060     1.071207   \n",
       "96    35.679821   35.744884   35.736008   35.730583     1.162267     1.079472   \n",
       "\n",
       "     char_capa_2  char_capa_3  char_capa_4  \n",
       "128     1.078900     1.080898     1.081935  \n",
       "89      1.070243     1.071443     1.071736  \n",
       "9       1.074246     1.076030     1.076883  \n",
       "76      1.070237     1.071492     1.072232  \n",
       "92      1.079837     1.081005     1.081767  \n",
       "..           ...          ...          ...  \n",
       "98      1.072463     1.073335     1.073706  \n",
       "21      1.071042     1.071674     1.072304  \n",
       "102     1.069810     1.071287     1.072626  \n",
       "62      1.072014     1.072860     1.074104  \n",
       "96      1.082149     1.083428     1.084170  \n",
       "\n",
       "[93 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatteryProject.ModelOne.trainer.Trainer at 0x7f7880b7c910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.set_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "                with_scaling=True)),\n",
       "  ('model',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'scaler': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "              with_scaling=True),\n",
       " 'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__quantile_range': (25.0, 75.0),\n",
       " 'scaler__with_centering': True,\n",
       " 'scaler__with_scaling': True,\n",
       " 'model__C': 1.0,\n",
       " 'model__class_weight': None,\n",
       " 'model__dual': False,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__intercept_scaling': 1,\n",
       " 'model__l1_ratio': None,\n",
       " 'model__max_iter': 1000,\n",
       " 'model__multi_class': 'auto',\n",
       " 'model__n_jobs': None,\n",
       " 'model__penalty': 'l2',\n",
       " 'model__random_state': None,\n",
       " 'model__solver': 'lbfgs',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'model__penalty' : ['l2', 'none'],\n",
    "        'model__solver' : ['lbfgs', 'sag'],\n",
    "        'model__C' : [0.1, 0.5, 1.0, 5.0, 10.0] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1502: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/tom/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatteryProject.ModelOne.trainer.Trainer at 0x7f7880b7c910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77     True\n",
       "111    True\n",
       "123    True\n",
       "134    True\n",
       "64     True\n",
       "Name: 549, dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.grid_search.best_estimator_.predict(trainer.X_train.iloc[10:15,:]) == trainer.y_train.iloc[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_model__C', 'param_model__penalty', 'param_model__solver', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.grid_search.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.926829268292683,\n",
       " 'precision': 0.9565217391304348,\n",
       " 'roc_auc': 0.9289215686274509}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.print_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d4876b27052dc26ce51ff7bd22356f05edb098ec8f23ba948ba7d36883e4605e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
